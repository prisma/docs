---
title: 'Deploy Prisma'
metaTitle: 'Deploy projects using Prisma to production'
metaDescription: 'Learn more about the different deployment paradigms for Node.js applications and how they affect deploying an application using Prisma Client.'
tocDepth: 2
---

<TopBlock>

Projects using Prisma Client can be deployed to many different cloud platforms. Given the variety of cloud platforms and different names, it's noteworthy to mention the different deployment paradigms, as they affect the way you deploy an application using Prisma Client.

</TopBlock>

## Deployment paradigms

Each paradigm has different tradeoffs that affect the performance, scalability, and operational costs of your application.

Moreover, the user traffic pattern of your application is also an important factor to consider. For example, any application with consistent user traffic may be better suited for a [continuously running paradigm](#long-running-process-paas), whereas an application with sudden spikes may be better suited to [serverless](#serverless-faas).

### Long-running process (PaaS)

Your application is [traditionally deployed](./traditional-deployments) if a Node.js process is continuously running and handles multiple requests at the same time. Your application can be deployed to a Platform-as-a-Service like [Heroku](./traditional-deployments/deploying-to-heroku), [Koyeb](./traditional-deployments/deploying-to-koyeb), as a Docker container to Kubernetes, or as a Node.js process on a virtual machine or good old bare metal server.

See also: [Connection management in long-running processes](/guides/performance-and-optimization/connection-management#long-running-processes)

### Serverless Functions (FaaS)

Your application is [serverless](./serverless-deployments) if the Node.js processes of your application (or subsets of it broken into functions) are started as requests come in, and each function only handles one request at a time.

Serverless environments have the concept of warm starts, which means that for subsequent invocations of the same function, it may use an already existing container that has the allocated processes, memory, file system (`/tmp` is writable on AWS Lambda), and even DB connection still available.

Typically, any piece of code [outside the handler](https://docs.aws.amazon.com/lambda/latest/dg/gettingstarted-features.html#gettingstarted-features-programmingmodel) remains initialized.

See also: [Connection management in serverless environments](/guides/performance-and-optimization/connection-management#serverless-environments-faas)

### Edge Functions (Distributed FaaS)

Your application is [edge deployed](./edge-deployments) if your application is [serverless](#serverless-faas) and the functions are distributed across one or more regions close to the user.

Typically, edge environments also have a different runtime than a traditional or serverless environment, leading to common APIs being unavailable.
