# Accepted status codes - aligned with linkspector config
accept = [200, 201, 204, 304, 403, 429]

# Cache results to speed up subsequent runs
cache = true

# Maximum number of retries per link
max_retries = 3

# Timeout per request in seconds
timeout = 20

# Maximum number of concurrent network requests
max_concurrency = 16

# Exclude localhost and local URLs
exclude = [
    # Localhost URLs from examples
    "http://localhost.*",
    "https://localhost.*",
    
    # Relative paths (checked by build process)
    "^/.*",
    
    # MySQL documentation (returns 403 for automated requests)
    "https://dev.mysql.com/.*",
    "https://www.mysql.com/.*",
    
    # NPM packages (returns 403 for automated requests)
    "https://www.npmjs.com/.*",
    
    # OpenAI platform (returns 403 for automated requests)
    "https://openai.com/.*",
    "https://platform.openai.com/.*",
    
    # Cloudflare (returns 403 for automated requests)
    "https://dash.cloudflare.com/.*",
    "https://playground.ai.cloudflare.com/.*",
    
    # CockroachDB blog (certificate issues in CI)
    "https://www.cockroachlabs.com/blog/.*",
]

# Exclude email addresses
exclude_mail = true

# Include files with these extensions
include = ["**/*.md", "**/*.mdx", "**/*.html"]

# Use custom headers to avoid bot detection
[headers]
"User-Agent" = "Mozilla/5.0 (compatible; Link Checker/1.0)"